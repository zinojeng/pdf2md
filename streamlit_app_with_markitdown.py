import streamlit as st
from llama_parse import LlamaParse
import os
import shutil
import time
from typing import Optional, Dict
from markitdown import MarkItDown

# è¨­ç½®é é¢æ¨™é¡Œ
st.set_page_config(
    page_title="å¤šæ¨¡æ…‹ PDF è§£æå™¨ - æ™ºèƒ½å‚™æ´ç‰ˆ",
    page_icon="ğŸ“„",
    layout="wide"
)

# åˆå§‹åŒ– session state
if 'parsing_history' not in st.session_state:
    st.session_state.parsing_history = []

# å´é‚Šæ¬„ API é‡‘é‘°è¼¸å…¥
st.sidebar.header("API è¨­å®š")

# API é‡‘é‘°è¼¸å…¥æ¬„ä½
gemini_api_key = st.sidebar.text_input(
    "Gemini API Key",
    type="password",
    help="å¾ Google AI Studio (https://aistudio.google.com/app/apikey) ç²å–ã€‚ä½¿ç”¨ Google å¸³è™Ÿç™»å…¥å¾Œå³å¯å‰µå»º API é‡‘é‘°ã€‚"
)
llama_cloud_api_key = st.sidebar.text_input(
    "Llama Cloud API Key (é¸æ“‡æ€§)",
    type="password",
    help="å¾ LlamaCloud (https://cloud.llamaindex.ai/) ç²å–ã€‚è‹¥ç„¡ API Key æˆ–é¡åº¦ç”¨å®Œï¼Œå°‡è‡ªå‹•ä½¿ç”¨ MarkItDown æœ¬åœ°è§£æã€‚"
)

st.sidebar.markdown("---")

# æ¨¡å‹é¸æ“‡
st.sidebar.subheader("ğŸ¤– é¸æ“‡ Gemini æ¨¡å‹")
model_choice = st.sidebar.selectbox(
    "æ¨¡å‹ç‰ˆæœ¬",
    options=[
        "gemini-2.0-flash",      # æ–°ç‰ˆæœ¬è¼ƒå°‘è§¸ç™¼ recitation
        "gemini-1.5-flash",      # èˆŠç‰ˆå¿«é€Ÿæ¨¡å‹
        "gemini-1.5-pro"         # èˆŠç‰ˆå°ˆæ¥­æ¨¡å‹
    ],
    index=0,
    help="é¸æ“‡è¦ä½¿ç”¨çš„ Gemini æ¨¡å‹ç‰ˆæœ¬ï¼ˆå»ºè­°ä½¿ç”¨ 2.0 ç‰ˆæœ¬ï¼‰"
)

# æ¨¡å‹èªªæ˜
model_descriptions = {
    "gemini-2.0-flash": "âš¡ æ¨è–¦ï¼šæœ€æ–°ç‰ˆæœ¬ï¼Œè¼ƒå°‘è§¸ç™¼å…§å®¹æ”¿ç­–é™åˆ¶",
    "gemini-1.5-flash": "ğŸš€ å¿«é€Ÿè™•ç†ï¼Œé©åˆä¸€èˆ¬æ–‡ä»¶",
    "gemini-1.5-pro": "ğŸ† é«˜å“è³ªï¼Œä½†å¯èƒ½è§¸ç™¼æ›´å¤šå…§å®¹é™åˆ¶"
}
st.sidebar.info(model_descriptions.get(model_choice, "æ¨™æº–æ¨¡å‹"))

# è§£ææ¨¡å¼é¸æ“‡
st.sidebar.markdown("---")
st.sidebar.subheader("âš™ï¸ è§£æè¨­å®š")
parsing_mode = st.sidebar.radio(
    "è§£ææ¨¡å¼",
    options=[
        "æ™ºèƒ½æ¨¡å¼ï¼ˆæ¨è–¦ï¼‰",
        "LlamaParse å„ªå…ˆ",
        "MarkItDown æœ¬åœ°è§£æ"
    ],
    index=0,
    help="""
    - æ™ºèƒ½æ¨¡å¼ï¼šå„ªå…ˆ LlamaParseï¼Œå¤±æ•—è‡ªå‹•åˆ‡æ›åˆ° MarkItDown
    - LlamaParse å„ªå…ˆï¼šåƒ…ä½¿ç”¨ LlamaParseï¼ˆéœ€è¦APIé¡åº¦ï¼‰
    - MarkItDown æœ¬åœ°è§£æï¼šåƒ…ä½¿ç”¨ Microsoft MarkItDownï¼ˆå®Œå…¨æœ¬åœ°ï¼‰
    """
)

# é€²éšé¸é …
with st.sidebar.expander("é€²éšé¸é …"):
    auto_retry = st.checkbox("é‡åˆ°éŒ¯èª¤æ™‚è‡ªå‹•é‡è©¦", value=True)
    max_retries = st.number_input("æœ€å¤§é‡è©¦æ¬¡æ•¸", min_value=1, max_value=3, value=2)
    show_debug_info = st.checkbox("é¡¯ç¤ºé™¤éŒ¯è³‡è¨Š", value=False)

# å°‡ API é‡‘é‘°è¨­ç½®ç‚ºç’°å¢ƒè®Šæ•¸
if gemini_api_key:
    os.environ["GEMINI_API_KEY"] = gemini_api_key
if llama_cloud_api_key:
    os.environ["LLAMA_CLOUD_API_KEY"] = llama_cloud_api_key

st.sidebar.markdown("---")

# å´é‚Šæ¬„ä½¿ç”¨èªªæ˜
st.sidebar.markdown("""
## ğŸ“– ä½¿ç”¨èªªæ˜
1. è¼¸å…¥ Gemini API é‡‘é‘°ï¼ˆLlamaParse éœ€è¦ï¼‰
2. é¸æ“‡è§£ææ¨¡å¼
3. ä¸Šå‚³ PDF æ–‡ä»¶
4. é»æ“Šã€Œé–‹å§‹è§£æã€
5. ä¸‹è¼‰ Markdown çµæœ

## âœ¨ ç‰¹è‰²åŠŸèƒ½
- **MarkItDown å‚™æ´**ï¼šç•¶ LlamaParse å¤±æ•—æ™‚è‡ªå‹•åˆ‡æ›
- **æ™ºèƒ½éŒ¯èª¤è™•ç†**ï¼šè‡ªå‹•åµæ¸¬ä¸¦è™•ç†å„ç¨®éŒ¯èª¤
- **å®Œå…¨æœ¬åœ°é¸é …**ï¼šä½¿ç”¨ MarkItDown ä¸éœ€ä»»ä½• API
""")

# æ·»åŠ ä½œè€…è³‡è¨Š
st.sidebar.markdown("---")
st.sidebar.markdown("""
## é—œæ–¼
æ•´åˆ Microsoft MarkItDown ä½œç‚ºå‚™æ´æ–¹æ¡ˆ
Code by Doctor Tseng @ Tungs' Hospital
""")

# ä¸»é é¢æ¨™é¡Œå’Œèªªæ˜
st.title("ğŸ“„ å¤šæ¨¡æ…‹ PDF è§£æå™¨ - æ™ºèƒ½å‚™æ´ç‰ˆ")

# æ·»åŠ ç‹€æ…‹æŒ‡ç¤ºå™¨
col1, col2, col3 = st.columns(3)
with col1:
    if llama_cloud_api_key:
        st.success("âœ… LlamaParse å·²å°±ç·’")
    else:
        st.info("â„¹ï¸ LlamaParse æœªè¨­å®š")
with col2:
    st.success("âœ… MarkItDown å·²å°±ç·’")
with col3:
    if gemini_api_key:
        st.success(f"âœ… {model_choice} å·²å°±ç·’")
    else:
        st.warning("âš ï¸ Gemini æœªè¨­å®š")

st.markdown("""
### æ™ºèƒ½æ–‡ä»¶è§£æï¼Œå¤šé‡å‚™æ´æ©Ÿåˆ¶

æ­¤å·¥å…·æ•´åˆ **LlamaParse** èˆ‡ **Microsoft MarkItDown**ï¼Œæä¾›æœ€å¯é çš„ PDF è§£ææ–¹æ¡ˆï¼š
- ç•¶ LlamaParse é‡åˆ° **recitation éŒ¯èª¤**æ™‚ï¼Œè‡ªå‹•åˆ‡æ›åˆ° MarkItDown
- ç•¶ **API é¡åº¦ç”¨å®Œ**æ™‚ï¼Œä½¿ç”¨æœ¬åœ° MarkItDown è§£æ
- å®Œå…¨**æœ¬åœ°åŒ–é¸é …**ï¼Œä¸éœ€è¦ä»»ä½• API é‡‘é‘°
""")

def parse_with_markitdown(file_path: str) -> Dict:
    """
    ä½¿ç”¨ Microsoft MarkItDown è§£æ PDF

    Args:
        file_path: PDF æ–‡ä»¶è·¯å¾‘

    Returns:
        è§£æçµæœå­—å…¸
    """
    try:
        # åˆå§‹åŒ– MarkItDown
        md = MarkItDown()

        # è§£ææ–‡ä»¶
        with open(file_path, "rb") as f:
            result = md.convert_stream(f, file_path=file_path)

        if result and result.text_content:
            return {
                "success": True,
                "content": result.text_content,
                "method": "MarkItDown",
                "title": result.title if hasattr(result, 'title') else None
            }
        else:
            return {
                "success": False,
                "error": "MarkItDown ç„¡æ³•æå–å…§å®¹",
                "method": "MarkItDown"
            }

    except Exception as e:
        return {
            "success": False,
            "error": f"MarkItDown éŒ¯èª¤: {str(e)}",
            "method": "MarkItDown"
        }

def parse_with_llamaparse(file_path: str, model_choice: str) -> Dict:
    """
    ä½¿ç”¨ LlamaParse è§£æ PDF

    Args:
        file_path: PDF æ–‡ä»¶è·¯å¾‘
        model_choice: Gemini æ¨¡å‹é¸æ“‡

    Returns:
        è§£æçµæœå­—å…¸
    """
    try:
        # ä¿®æ”¹å…§å®¹æŒ‡å°ä»¥é¿å… recitation
        content_guideline = """
        Extract and restructure the document content:
        1. SUMMARIZE text sections, don't copy verbatim
        2. Extract DATA and STRUCTURE (tables, lists, headings)
        3. Focus on KEY INFORMATION and CONCEPTS
        4. Preserve technical terms, formulas, and numbers exactly
        5. Create an analytical summary rather than full text extraction
        6. For tables: convert to markdown format
        7. For figures: describe content and data trends
        """

        parser = LlamaParse(
            result_type="markdown",
            use_vendor_multimodal_model=True,
            vendor_multimodal_model_name=model_choice,
            system_prompt=content_guideline,
            invalidate_cache=True,
            verbose=False
        )

        # åŸ·è¡Œè§£æ
        json_objs = parser.get_json_result(file_path)

        if not json_objs or len(json_objs) == 0:
            return {
                "success": False,
                "error": "LlamaParse ç„¡æ³•æå–å…§å®¹",
                "method": "LlamaParse"
            }

        json_list = json_objs[0]["pages"]

        # çµ„åˆé é¢å…§å®¹
        content = []
        for i, page in enumerate(json_list):
            content.append(f"## Page {i+1}\n\n{page.get('md', '')}")

        return {
            "success": True,
            "content": "\n\n".join(content),
            "method": "LlamaParse",
            "pages": len(json_list)
        }

    except Exception as e:
        error_msg = str(e)
        error_type = "unknown"

        if "recitation" in error_msg.lower():
            error_type = "recitation"
        elif "credits" in error_msg.lower() or "quota" in error_msg.lower():
            error_type = "quota"
        elif "multimodal" in error_msg.lower():
            error_type = "multimodal"

        return {
            "success": False,
            "error": error_msg,
            "error_type": error_type,
            "method": "LlamaParse"
        }

def smart_parse(file_path: str, mode: str, model_choice: str,
                llama_key: Optional[str], options: Dict) -> Dict:
    """
    æ™ºèƒ½è§£æ PDFï¼Œæ ¹æ“šæ¨¡å¼å’ŒéŒ¯èª¤è‡ªå‹•é¸æ“‡æœ€ä½³æ–¹æ³•

    Args:
        file_path: PDF æ–‡ä»¶è·¯å¾‘
        mode: è§£ææ¨¡å¼
        model_choice: Gemini æ¨¡å‹
        llama_key: LlamaParse API key
        options: å…¶ä»–é¸é …

    Returns:
        è§£æçµæœ
    """
    results = []

    # MarkItDown æœ¬åœ°è§£ææ¨¡å¼
    if mode == "MarkItDown æœ¬åœ°è§£æ":
        st.info("ğŸ”§ ä½¿ç”¨ MarkItDown é€²è¡Œæœ¬åœ°è§£æ...")
        result = parse_with_markitdown(file_path)
        results.append(result)
        return result

    # LlamaParse å„ªå…ˆæ¨¡å¼
    elif mode == "LlamaParse å„ªå…ˆ":
        if not llama_key:
            st.warning("âš ï¸ æœªæä¾› LlamaParse API Keyï¼Œè‡ªå‹•åˆ‡æ›åˆ° MarkItDown")
            result = parse_with_markitdown(file_path)
            results.append(result)
            return result

        st.info(f"ğŸš€ ä½¿ç”¨ LlamaParse + {model_choice} è§£æ...")
        result = parse_with_llamaparse(file_path, model_choice)
        results.append(result)

        if not result["success"]:
            st.warning(f"âš ï¸ LlamaParse å¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")

            if options.get("auto_retry") and result.get("error_type") in ["recitation", "quota"]:
                st.info("ğŸ”„ è‡ªå‹•åˆ‡æ›åˆ° MarkItDown...")
                fallback_result = parse_with_markitdown(file_path)
                results.append(fallback_result)
                return fallback_result

        return result

    # æ™ºèƒ½æ¨¡å¼ï¼ˆæ¨è–¦ï¼‰
    else:  # æ™ºèƒ½æ¨¡å¼
        # å„ªå…ˆå˜—è©¦ LlamaParse
        if llama_key:
            st.info(f"ğŸš€ å˜—è©¦ LlamaParse + {model_choice}...")
            result = parse_with_llamaparse(file_path, model_choice)
            results.append(result)

            if result["success"]:
                st.success("âœ… LlamaParse è§£ææˆåŠŸ")
                return result
            else:
                error_type = result.get("error_type", "unknown")
                st.warning(f"âš ï¸ LlamaParse é‡åˆ°å•é¡Œ: {error_type}")

                # æ ¹æ“šéŒ¯èª¤é¡å‹æ±ºå®šæ˜¯å¦é‡è©¦
                if error_type == "recitation":
                    st.info("ğŸ“ æª¢æ¸¬åˆ°å…§å®¹æ”¿ç­–é™åˆ¶ï¼Œåˆ‡æ›åˆ° MarkItDown...")
                elif error_type == "quota":
                    st.info("ğŸ’³ API é¡åº¦ä¸è¶³ï¼Œåˆ‡æ›åˆ° MarkItDown...")
                elif options.get("auto_retry") and len(results) < options.get("max_retries", 2):
                    st.info(f"ğŸ”„ é‡è©¦ {len(results)}/{options.get('max_retries', 2)}...")
                    time.sleep(2)
                    retry_result = parse_with_llamaparse(file_path, model_choice)
                    results.append(retry_result)
                    if retry_result["success"]:
                        return retry_result

        # ä½¿ç”¨ MarkItDown ä½œç‚ºå‚™æ´
        st.info("ğŸ”§ ä½¿ç”¨ MarkItDown æœ¬åœ°è§£æ...")
        fallback_result = parse_with_markitdown(file_path)
        results.append(fallback_result)

        if fallback_result["success"]:
            st.success("âœ… MarkItDown è§£ææˆåŠŸ")

        return fallback_result

# ä¸»è¦ä»‹é¢
if not gemini_api_key and parsing_mode != "MarkItDown æœ¬åœ°è§£æ":
    st.warning("è«‹åœ¨å·¦å´è¼¸å…¥ Gemini API é‡‘é‘°ï¼Œæˆ–é¸æ“‡ MarkItDown æœ¬åœ°è§£ææ¨¡å¼")
else:
    # æ–‡ä»¶ä¸Šå‚³å€
    uploaded_file = st.file_uploader(
        "ä¸Šå‚³ PDF æ–‡ä»¶",
        type="pdf",
        help="æ”¯æ´å„ç¨® PDF æ ¼å¼ï¼ŒåŒ…æ‹¬æƒææª”æ¡ˆ"
    )

    if uploaded_file is not None:
        # å‰µå»ºè‡¨æ™‚ç›®éŒ„
        temp_dir = "temp_uploads"
        os.makedirs(temp_dir, exist_ok=True)

        # ä¿å­˜ä¸Šå‚³çš„æ–‡ä»¶
        file_path = os.path.join(temp_dir, uploaded_file.name)
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        # é¡¯ç¤ºæ–‡ä»¶ä¿¡æ¯
        col1, col2 = st.columns(2)
        with col1:
            st.success(f"âœ… å·²ä¸Šå‚³: {uploaded_file.name}")
        with col2:
            file_size_mb = uploaded_file.size / (1024 * 1024)
            st.info(f"ğŸ“Š å¤§å°: {file_size_mb:.2f} MB")

        # è§£ææŒ‰éˆ•
        if st.button("ğŸš€ é–‹å§‹è§£æ", type="primary", use_container_width=True):

            # å‰µå»ºé€²åº¦å®¹å™¨
            with st.spinner("è§£æä¸­..."):
                start_time = time.time()

                try:
                    # æº–å‚™é¸é …
                    options = {
                        "auto_retry": auto_retry,
                        "max_retries": max_retries,
                        "show_debug": show_debug_info
                    }

                    # åŸ·è¡Œæ™ºèƒ½è§£æ
                    result = smart_parse(
                        file_path,
                        parsing_mode,
                        model_choice,
                        llama_cloud_api_key,
                        options
                    )

                    # è¨ˆç®—è§£ææ™‚é–“
                    elapsed_time = time.time() - start_time

                    if result["success"]:
                        content = result["content"]

                        # æ·»åŠ å…ƒè³‡æ–™åˆ°å…§å®¹é–‹é ­
                        metadata = f"""---
title: {uploaded_file.name.replace('.pdf', '')}
parsed_by: {result.get('method', 'Unknown')}
model: {model_choice if result.get('method') == 'LlamaParse' else 'N/A'}
date: {time.strftime('%Y-%m-%d %H:%M:%S')}
time_taken: {elapsed_time:.2f}s
---

"""
                        full_content = metadata + content

                        # é¡¯ç¤ºæˆåŠŸè¨Šæ¯å’Œçµ±è¨ˆ
                        st.success(f"âœ… è§£æå®Œæˆï¼ä½¿ç”¨ {result.get('method', 'Unknown')}")

                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("è§£ææ–¹æ³•", result.get('method', 'Unknown'))
                        with col2:
                            st.metric("è€—æ™‚", f"{elapsed_time:.1f} ç§’")
                        with col3:
                            st.metric("å­—æ•¸", f"{len(content):,}")
                        with col4:
                            if result.get('pages'):
                                st.metric("é æ•¸", result['pages'])

                        # é¡¯ç¤ºé è¦½
                        with st.expander("ğŸ“ é è¦½è§£æçµæœ", expanded=True):
                            preview_length = min(2000, len(content))
                            st.markdown(content[:preview_length] + "..." if len(content) > preview_length else content)

                        # æä¾›ä¸‹è¼‰æŒ‰éˆ•
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è¼‰ Markdown æª”æ¡ˆ",
                            data=full_content,
                            file_name=uploaded_file.name.replace(".pdf", ".md"),
                            mime="text/markdown",
                            type="primary",
                            use_container_width=True
                        )

                        # è¨˜éŒ„åˆ°æ­·å²
                        st.session_state.parsing_history.append({
                            "filename": uploaded_file.name,
                            "method": result.get('method'),
                            "success": True,
                            "time": elapsed_time
                        })

                    else:
                        st.error(f"âŒ è§£æå¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")

                        # æä¾›å»ºè­°
                        st.info("""
                        ğŸ’¡ **å»ºè­°å˜—è©¦ï¼š**
                        1. åˆ‡æ›åˆ° MarkItDown æœ¬åœ°è§£ææ¨¡å¼
                        2. æª¢æŸ¥ PDF æ˜¯å¦æå£
                        3. å¦‚æœæ˜¯æƒææª”ï¼Œå¯èƒ½éœ€è¦ OCR è™•ç†
                        """)

                except Exception as e:
                    st.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

                    if show_debug_info:
                        st.exception(e)

                finally:
                    # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
                    if os.path.exists(temp_dir):
                        shutil.rmtree(temp_dir)

# é¡¯ç¤ºè§£ææ­·å²
if st.session_state.parsing_history:
    with st.expander("ğŸ“œ è§£ææ­·å²"):
        for record in st.session_state.parsing_history[-5:]:  # é¡¯ç¤ºæœ€è¿‘5ç­†
            col1, col2, col3 = st.columns(3)
            with col1:
                st.text(record['filename'])
            with col2:
                st.text(f"æ–¹æ³•: {record['method']}")
            with col3:
                st.text(f"è€—æ™‚: {record['time']:.1f}s")

# æ·»åŠ é å°¾
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>æ•´åˆ <strong>LlamaParse</strong> + <strong>Microsoft MarkItDown</strong></p>
    <p style='font-size: 0.9em;'>æ™ºèƒ½å‚™æ´æ©Ÿåˆ¶ï¼Œç¢ºä¿è§£ææˆåŠŸ | MIT License</p>
</div>
""", unsafe_allow_html=True)