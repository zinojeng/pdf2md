import streamlit as st
from llama_parse import LlamaParse
import os
import shutil
import json
import time
from typing import Optional, Dict, List
from pdf_parser_alternative import parse_pdf_with_fallbacks

# è¨­ç½®é é¢æ¨™é¡Œ
st.set_page_config(
    page_title="å¤šæ¨¡æ…‹ PDF è§£æå™¨ - Gemini 2.5",
    page_icon="ğŸ“„",
    layout="wide"
)

# å´é‚Šæ¬„ API é‡‘é‘°è¼¸å…¥
st.sidebar.header("API è¨­å®š")

# API é‡‘é‘°è¼¸å…¥æ¬„ä½
gemini_api_key = st.sidebar.text_input(
    "Gemini API Key",
    type="password",
    help="å¾ Google AI Studio (https://aistudio.google.com/app/apikey) ç²å–ã€‚ä½¿ç”¨ Google å¸³è™Ÿç™»å…¥å¾Œå³å¯å‰µå»º API é‡‘é‘°ã€‚"
)
llama_cloud_api_key = st.sidebar.text_input(
    "Llama Cloud API Key (é¸æ“‡æ€§)",
    type="password",
    help="å¾ LlamaCloud (https://cloud.llamaindex.ai/) ç²å–ã€‚è‹¥é¡åº¦ç”¨å®Œå¯ç•™ç©ºï¼Œå°‡ä½¿ç”¨æ›¿ä»£æ–¹æ¡ˆã€‚"
)

st.sidebar.markdown("---")

# æ¨¡å‹é¸æ“‡
st.sidebar.subheader("ğŸ¤– é¸æ“‡ Gemini æ¨¡å‹")
model_choice = st.sidebar.selectbox(
    "æ¨¡å‹ç‰ˆæœ¬",
    options=[
        "gemini-2.0-flash",  # æ”¹ç”¨ 2.0 ç‰ˆæœ¬ï¼Œè¼ƒå°‘è§¸ç™¼ recitation
        "gemini-1.5-pro",
        "gemini-1.5-flash"
    ],
    index=0,
    help="é¸æ“‡è¦ä½¿ç”¨çš„ Gemini æ¨¡å‹ç‰ˆæœ¬"
)

# æ¨¡å‹èªªæ˜
model_descriptions = {
    "gemini-2.0-flash": "âš¡ æœ€æ–°ç‰ˆæœ¬ï¼Œè¼ƒå°‘è§¸ç™¼å…§å®¹æ”¿ç­–é™åˆ¶",
    "gemini-1.5-pro": "ğŸ† é«˜å“è³ªï¼Œé©åˆè¤‡é›œæ–‡ä»¶",
    "gemini-1.5-flash": "ğŸš€ å¿«é€Ÿè™•ç†ï¼Œé©åˆä¸€èˆ¬æ–‡ä»¶"
}
st.sidebar.info(model_descriptions.get(model_choice, "æ¨™æº–æ¨¡å‹"))

# è§£ææ¨¡å¼é¸æ“‡
st.sidebar.markdown("---")
st.sidebar.subheader("âš™ï¸ è§£æè¨­å®š")
parsing_mode = st.sidebar.radio(
    "è§£ææ¨¡å¼",
    options=["æ™ºèƒ½æ¨¡å¼", "LlamaParseå„ªå…ˆ", "æœ¬åœ°è§£æ"],
    index=0,
    help="""
    - æ™ºèƒ½æ¨¡å¼ï¼šè‡ªå‹•é¸æ“‡æœ€ä½³æ–¹æ¡ˆ
    - LlamaParseå„ªå…ˆï¼šå„ªå…ˆä½¿ç”¨ LlamaParseï¼ˆéœ€è¦APIé¡åº¦ï¼‰
    - æœ¬åœ°è§£æï¼šåƒ…ä½¿ç”¨æœ¬åœ°å·¥å…·ï¼ˆä¸éœ€è¦ LlamaParseï¼‰
    """
)

# é€²éšé¸é …
with st.sidebar.expander("é€²éšé¸é …"):
    retry_on_error = st.checkbox("é‡åˆ°éŒ¯èª¤æ™‚è‡ªå‹•é‡è©¦", value=True)
    max_retries = st.number_input("æœ€å¤§é‡è©¦æ¬¡æ•¸", min_value=1, max_value=5, value=3)
    chunk_pages = st.checkbox("åˆ†æ®µè™•ç†å¤§å‹æ–‡ä»¶", value=True,
                              help="å°‡å¤§å‹PDFåˆ†æˆå°æ®µè™•ç†ï¼Œé¿å…è§¸ç™¼å…§å®¹æ”¿ç­–")
    pages_per_chunk = st.number_input("æ¯æ®µé æ•¸", min_value=5, max_value=50, value=10)

# å°‡ API é‡‘é‘°è¨­ç½®ç‚ºç’°å¢ƒè®Šæ•¸
if gemini_api_key:
    os.environ["GEMINI_API_KEY"] = gemini_api_key
if llama_cloud_api_key:
    os.environ["LLAMA_CLOUD_API_KEY"] = llama_cloud_api_key

st.sidebar.markdown("---")

# å´é‚Šæ¬„ä½¿ç”¨èªªæ˜
st.sidebar.markdown("""
## ğŸ“– ä½¿ç”¨èªªæ˜
1. è¼¸å…¥ Gemini API é‡‘é‘°ï¼ˆå¿…è¦ï¼‰
2. è¼¸å…¥ LlamaParse API é‡‘é‘°ï¼ˆé¸æ“‡æ€§ï¼‰
3. é¸æ“‡è§£ææ¨¡å¼
4. ä¸Šå‚³ PDF æ–‡ä»¶
5. é»æ“Šã€Œé–‹å§‹è§£æã€
6. ä¸‹è¼‰ Markdown çµæœ

## âš ï¸ å¸¸è¦‹å•é¡Œè§£æ±º
- **RecitationéŒ¯èª¤**ï¼šç³»çµ±æœƒè‡ªå‹•åˆ‡æ›åˆ°æ›¿ä»£æ–¹æ¡ˆ
- **APIé¡åº¦ä¸è¶³**ï¼šä½¿ç”¨æœ¬åœ°è§£ææ¨¡å¼
- **å¤§å‹æ–‡ä»¶**ï¼šå•Ÿç”¨åˆ†æ®µè™•ç†
""")

# æ·»åŠ ä½œè€…è³‡è¨Š
st.sidebar.markdown("---")
st.sidebar.markdown("""
## é—œæ–¼ä½œè€…
Code by Doctor Tseng
Endocrinologist at Tungs' Taichung Metroharbor Hospital
""")

# ä¸»é é¢æ¨™é¡Œå’Œèªªæ˜
st.title("ğŸ“„ å¤šæ¨¡æ…‹ PDF è§£æå™¨ï¼ˆå¢å¼·ç‰ˆï¼‰")
st.markdown("""
### æ™ºèƒ½æ–‡ä»¶è§£æï¼Œè‡ªå‹•è™•ç†éŒ¯èª¤

æ­¤å·¥å…·æ•´åˆå¤šç¨®è§£ææ–¹æ¡ˆï¼Œç•¶é‡åˆ° API é™åˆ¶æˆ–å…§å®¹æ”¿ç­–å•é¡Œæ™‚æœƒè‡ªå‹•åˆ‡æ›åˆ°æ›¿ä»£æ–¹æ¡ˆã€‚

#### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½
- âœ… **æ™ºèƒ½éŒ¯èª¤è™•ç†** - è‡ªå‹•åµæ¸¬ä¸¦è™•ç† recitation æ”¿ç­–éŒ¯èª¤
- âœ… **å¤šé‡è§£æå¼•æ“** - LlamaParseã€PyPDF2ã€pdfplumberã€PyMuPDF
- âœ… **åˆ†æ®µè™•ç†** - é¿å…è§¸ç™¼å…§å®¹æ”¿ç­–é™åˆ¶
- âœ… **è‡ªå‹•é‡è©¦æ©Ÿåˆ¶** - é‡åˆ°éŒ¯èª¤æ™‚æ™ºèƒ½é‡è©¦
- âœ… **é›¢ç·šå‚™æ´** - APIé¡åº¦ç”¨å®Œæ™‚å¯ä½¿ç”¨æœ¬åœ°è§£æ
""")

def parse_with_llama_parse(file_path: str, model_choice: str, chunk_mode: bool = False,
                           start_page: int = 0, end_page: Optional[int] = None) -> Dict:
    """
    ä½¿ç”¨ LlamaParse è§£æ PDF

    Args:
        file_path: PDF æ–‡ä»¶è·¯å¾‘
        model_choice: Gemini æ¨¡å‹é¸æ“‡
        chunk_mode: æ˜¯å¦ä½¿ç”¨åˆ†æ®µæ¨¡å¼
        start_page: é–‹å§‹é æ•¸
        end_page: çµæŸé æ•¸

    Returns:
        è§£æçµæœå­—å…¸
    """
    try:
        # ä¿®æ”¹å…§å®¹æŒ‡å°ä»¥é¿å… recitation
        content_guideline = """
        Extract and reformat the document content following these rules:
        1. Focus on structure and data, not exact wording
        2. Summarize lengthy paragraphs while preserving key information
        3. Extract tables as structured data
        4. Describe figures and charts focusing on data trends
        5. Use your own words to explain concepts
        6. Preserve technical terms, numbers, and formulas exactly
        7. DO NOT copy verbatim text passages
        8. Create an outline-based summary rather than full text extraction
        """

        # æ·»åŠ é é¢ç¯„åœåƒæ•¸
        extra_info = {}
        if chunk_mode and end_page:
            extra_info = {
                "page_range": f"{start_page}-{end_page}",
            }

        parser = LlamaParse(
            result_type="markdown",
            use_vendor_multimodal_model=True,
            vendor_multimodal_model_name=model_choice,
            system_prompt=content_guideline,  # ä½¿ç”¨ system_prompt ä»£æ›¿ deprecated çš„åƒæ•¸
            invalidate_cache=True,
            **extra_info
        )

        # åŸ·è¡Œè§£æ
        json_objs = parser.get_json_result(file_path)

        if not json_objs or len(json_objs) == 0:
            return {"error": "ç„¡æ³•å¾ PDF ä¸­è§£æå‡ºå…§å®¹", "type": "empty_result"}

        json_list = json_objs[0]["pages"]

        # çµ„åˆè§£æçµæœ
        content = []
        for page in json_list:
            content.append(page.get('md', ''))

        return {
            "success": True,
            "content": "\n\n".join(content),
            "pages": len(json_list)
        }

    except Exception as e:
        error_msg = str(e)

        # åˆ†æéŒ¯èª¤é¡å‹
        if "recitation" in error_msg.lower():
            return {"error": "å…§å®¹æ”¿ç­–é™åˆ¶ï¼ˆrecitationï¼‰", "type": "recitation"}
        elif "credits" in error_msg.lower() or "quota" in error_msg.lower():
            return {"error": "API é¡åº¦ä¸è¶³", "type": "quota"}
        elif "multimodal_error" in error_msg.lower():
            return {"error": "å¤šæ¨¡æ…‹è™•ç†éŒ¯èª¤", "type": "multimodal", "details": error_msg}
        else:
            return {"error": f"è§£æéŒ¯èª¤ï¼š{error_msg}", "type": "unknown"}

def handle_recitation_error(file_path: str, error_details: str) -> Optional[str]:
    """
    è™•ç† recitation éŒ¯èª¤ï¼Œæå–å¤±æ•—çš„é é¢ä¸¦ä½¿ç”¨æ›¿ä»£æ–¹æ³•

    Args:
        file_path: PDF æ–‡ä»¶è·¯å¾‘
        error_details: éŒ¯èª¤è©³æƒ…

    Returns:
        è§£æçµæœæˆ– None
    """
    # å¾éŒ¯èª¤è¨Šæ¯ä¸­æå–å¤±æ•—çš„é é¢
    import re
    failed_pages = re.findall(r'Page (\d+):', error_details)
    failed_pages = [int(p) for p in failed_pages]

    if failed_pages:
        st.warning(f"æª¢æ¸¬åˆ° {len(failed_pages)} é è§¸ç™¼å…§å®¹æ”¿ç­–ï¼Œå°‡ä½¿ç”¨æ›¿ä»£æ–¹æ³•è™•ç†é€™äº›é é¢")

    # ä½¿ç”¨æ›¿ä»£æ–¹æ³•
    return None

def smart_parse_pdf(file_path: str, gemini_api_key: str, llama_api_key: Optional[str],
                    mode: str, model_choice: str, options: Dict) -> str:
    """
    æ™ºèƒ½ PDF è§£æä¸»å‡½æ•¸

    Args:
        file_path: PDF æ–‡ä»¶è·¯å¾‘
        gemini_api_key: Gemini API é‡‘é‘°
        llama_api_key: LlamaParse API é‡‘é‘°ï¼ˆå¯é¸ï¼‰
        mode: è§£ææ¨¡å¼
        model_choice: æ¨¡å‹é¸æ“‡
        options: å…¶ä»–é¸é …

    Returns:
        è§£æçµæœï¼ˆMarkdown æ ¼å¼ï¼‰
    """
    result = None
    retry_count = 0
    max_retries = options.get("max_retries", 3)

    # æ ¹æ“šæ¨¡å¼é¸æ“‡è§£æç­–ç•¥
    if mode == "æœ¬åœ°è§£æ" or not llama_api_key:
        st.info("ä½¿ç”¨æœ¬åœ°è§£æå·¥å…·...")
        result = parse_pdf_with_fallbacks(file_path, gemini_api_key, model_choice)

    elif mode == "LlamaParseå„ªå…ˆ" or mode == "æ™ºèƒ½æ¨¡å¼":
        while retry_count < max_retries:
            st.info(f"å˜—è©¦ä½¿ç”¨ LlamaParse è§£æ... (ç¬¬ {retry_count + 1} æ¬¡)")

            # å˜—è©¦ LlamaParse
            parse_result = parse_with_llama_parse(
                file_path,
                model_choice,
                chunk_mode=options.get("chunk_pages", False),
            )

            if parse_result.get("success"):
                result = parse_result["content"]
                st.success("âœ… LlamaParse è§£ææˆåŠŸï¼")
                break

            else:
                error_type = parse_result.get("type", "unknown")
                error_msg = parse_result.get("error", "æœªçŸ¥éŒ¯èª¤")

                st.warning(f"âš ï¸ {error_msg}")

                # æ ¹æ“šéŒ¯èª¤é¡å‹æ±ºå®šç­–ç•¥
                if error_type == "recitation":
                    st.info("æª¢æ¸¬åˆ°å…§å®¹æ”¿ç­–é™åˆ¶ï¼Œåˆ‡æ›åˆ°æœ¬åœ°è§£æ...")
                    result = parse_pdf_with_fallbacks(file_path, gemini_api_key, model_choice)
                    break

                elif error_type == "quota":
                    st.info("API é¡åº¦ä¸è¶³ï¼Œåˆ‡æ›åˆ°æœ¬åœ°è§£æ...")
                    result = parse_pdf_with_fallbacks(file_path, gemini_api_key, model_choice)
                    break

                elif error_type == "multimodal":
                    # å¦‚æœæ˜¯éƒ¨åˆ†é é¢å¤±æ•—ï¼Œå˜—è©¦è™•ç†
                    if "Page errors" in parse_result.get("details", ""):
                        alternative = handle_recitation_error(file_path, parse_result["details"])
                        if alternative:
                            result = alternative
                            break

                    # é‡è©¦æˆ–åˆ‡æ›
                    retry_count += 1
                    if retry_count >= max_retries:
                        st.info("å¤šæ¬¡å˜—è©¦å¤±æ•—ï¼Œåˆ‡æ›åˆ°æœ¬åœ°è§£æ...")
                        result = parse_pdf_with_fallbacks(file_path, gemini_api_key, model_choice)
                        break
                    else:
                        time.sleep(2)  # ç­‰å¾…å¾Œé‡è©¦

                else:
                    retry_count += 1
                    if retry_count >= max_retries:
                        st.info("åˆ‡æ›åˆ°æœ¬åœ°è§£æ...")
                        result = parse_pdf_with_fallbacks(file_path, gemini_api_key, model_choice)
                        break

    return result or "ç„¡æ³•è§£ææ–‡ä»¶"

# æª¢æŸ¥æ˜¯å¦å·²è¼¸å…¥å¿…è¦çš„ API é‡‘é‘°
if not gemini_api_key:
    st.warning("è«‹åœ¨å·¦å´è¼¸å…¥ Gemini API é‡‘é‘°")
else:
    # æ–‡ä»¶ä¸Šå‚³å€
    uploaded_file = st.file_uploader("ä¸Šå‚³PDFæ–‡ä»¶", type="pdf")

    # è§£ææŒ‰éˆ•
    if uploaded_file is not None:
        # å‰µå»ºè‡¨æ™‚ç›®éŒ„
        temp_dir = "temp_uploads"
        os.makedirs(temp_dir, exist_ok=True)

        # ä¿å­˜ä¸Šå‚³çš„æ–‡ä»¶
        file_path = os.path.join(temp_dir, uploaded_file.name)
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        # é¡¯ç¤ºæ–‡ä»¶ä¿¡æ¯
        col1, col2 = st.columns(2)
        with col1:
            st.success(f"âœ… æˆåŠŸä¸Šå‚³: {uploaded_file.name}")
        with col2:
            st.info(f"ğŸ“Š æ–‡ä»¶å¤§å°: {uploaded_file.size / 1024:.2f} KB")

        # è§£ææŒ‰éˆ•
        if st.button("ğŸš€ é–‹å§‹è§£æ", type="primary", use_container_width=True):

            # å‰µå»ºé€²åº¦å®¹å™¨
            progress_container = st.container()

            with progress_container:
                progress_bar = st.progress(0)
                status_text = st.empty()

                try:
                    # å‰µå»ºè¼¸å‡ºç›®éŒ„
                    output_dir = "parsed_results"
                    os.makedirs(output_dir, exist_ok=True)

                    # æ›´æ–°é€²åº¦
                    progress_bar.progress(20)
                    status_text.text("ğŸ“¤ æº–å‚™è§£ææ–‡ä»¶...")

                    # æº–å‚™é¸é …
                    options = {
                        "retry_on_error": retry_on_error,
                        "max_retries": max_retries,
                        "chunk_pages": chunk_pages,
                        "pages_per_chunk": pages_per_chunk
                    }

                    # åŸ·è¡Œæ™ºèƒ½è§£æ
                    progress_bar.progress(40)
                    status_text.text(f"ğŸ”„ ä½¿ç”¨ {model_choice} é€²è¡Œè§£æ...")

                    content = smart_parse_pdf(
                        file_path,
                        gemini_api_key,
                        llama_cloud_api_key,
                        parsing_mode,
                        model_choice,
                        options
                    )

                    progress_bar.progress(80)
                    status_text.text("ğŸ’¾ ä¿å­˜è§£æçµæœ...")

                    # å„²å­˜è§£æçµæœ
                    output_file = os.path.join(output_dir, uploaded_file.name.replace(".pdf", ".md"))
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(content)

                    progress_bar.progress(100)
                    status_text.text("âœ… è§£æå®Œæˆï¼")

                    # é¡¯ç¤ºæˆåŠŸè¨Šæ¯
                    st.success(f"âœ… æˆåŠŸè§£ææ–‡ä»¶ï¼")

                    # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("å­—æ•¸", f"{len(content):,}")
                    with col2:
                        st.metric("è¡Œæ•¸", f"{content.count(chr(10)):,}")
                    with col3:
                        st.metric("æ®µè½æ•¸", f"{content.count(chr(10)*2):,}")

                    # é¡¯ç¤ºé è¦½
                    with st.expander("ğŸ“ é è¦½è§£æçµæœ", expanded=True):
                        preview_length = min(2000, len(content))
                        st.markdown(content[:preview_length] + "..." if len(content) > preview_length else content)

                    # æä¾›ä¸‹è¼‰æŒ‰éˆ•
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰å®Œæ•´ Markdown æª”æ¡ˆ",
                        data=content,
                        file_name=uploaded_file.name.replace(".pdf", ".md"),
                        mime="text/markdown",
                        type="primary",
                        use_container_width=True
                    )

                except Exception as e:
                    st.error(f"âŒ è§£æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                    st.info("ğŸ’¡ å»ºè­°ï¼šè«‹å˜—è©¦åˆ‡æ›åˆ°ã€Œæœ¬åœ°è§£æã€æ¨¡å¼æˆ–è¯ç¹«æŠ€è¡“æ”¯æ´")

                finally:
                    # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
                    if os.path.exists(temp_dir):
                        shutil.rmtree(temp_dir)
                    if os.path.exists(output_dir):
                        shutil.rmtree(output_dir)

# æ·»åŠ é å°¾
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>ç”± <strong>Gemini API</strong> èˆ‡ <strong>å¤šé‡è§£æå¼•æ“</strong> æä¾›æ”¯æŒ</p>
    <p style='font-size: 0.9em;'>å¢å¼·ç‰ˆ - è‡ªå‹•è™•ç†å…§å®¹æ”¿ç­–é™åˆ¶ | MIT License</p>
</div>
""", unsafe_allow_html=True)